{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Assignment1_Sentiment_Analysis.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"193XdHK8SmAVmjG36QyoKX8xh265uIx_w","authorship_tag":"ABX9TyP/s2LJCjUkDUUwcOgLVijP"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"1xgW1tJTzMx9","executionInfo":{"status":"ok","timestamp":1603294546548,"user_tz":-330,"elapsed":4506,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}},"outputId":"d82abc96-2f49-4877-dfff-3356afa29468","colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["# 1 A. Import Libraries\n","import pandas as pd\n","import tensorflow_hub as hub\n","import tensorflow as tf\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","import keras\n","import spacy\n","import re\n","from tensorflow.keras import regularizers\n","!pip install pycm\n","from pycm import ConfusionMatrix"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pycm in /usr/local/lib/python3.6/dist-packages (2.9)\n","Requirement already satisfied: art>=1.8 in /usr/local/lib/python3.6/dist-packages (from pycm) (4.9)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pycm) (1.18.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AuDBp1TFPx--","executionInfo":{"status":"ok","timestamp":1603298474258,"user_tz":-330,"elapsed":5979,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}},"outputId":"fc155cfd-07ec-4799-abd7-bd5c41f3ccb3","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# 1 B. Importing data set from  Google drive \n","\n","re.compile('<title>(.*)</title>')\n","\n","trainfile = \"/content/drive/My Drive/Colab Notebooks/training.1600000.processed.noemoticon.csv\"\n","DATASET_COLUMNS  = [\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n","DATASET_ENCODING = \"ISO-8859-1\"\n","df_train = pd.read_csv(trainfile,\n","                      encoding=DATASET_ENCODING , names=DATASET_COLUMNS)\n","y_label=df_train.iloc[:,0].values\n","print(1)\n","\n","NUMTRAIN = 800000\n","train_set = df_train[['ids','sentiment', 'text']].sample(NUMTRAIN)\n","X_train = train_set.drop(\"sentiment\", axis=1) # drop labels for training set\n","y_train = train_set[\"sentiment\"].copy()\n","\n","NUMTEST = 100000\n","test_set = df_train[['ids','sentiment', 'text']].sample(NUMTEST)\n","X_test = test_set.drop(\"sentiment\", axis=1) # drop labels for training set\n","y_test = test_set[\"sentiment\"].copy()\n","print(2)\n","\n","label_encoder = LabelEncoder()\n","y_train = label_encoder.fit_transform(y_train)                    \n","y_train = keras.utils.to_categorical(y_train)\n","\n","y_test = label_encoder.fit_transform(y_test)                    \n","y_test = keras.utils.to_categorical(y_test)"],"execution_count":70,"outputs":[{"output_type":"stream","text":["1\n","2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IeSW62c5Cy9p","executionInfo":{"status":"ok","timestamp":1603303751113,"user_tz":-330,"elapsed":1410,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}},"outputId":"e389a13d-c321-4e17-c931-525e943d42f1","colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["# 1 C. Check GPU availability\n","print(\"Version: \", tf.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n"],"execution_count":81,"outputs":[{"output_type":"stream","text":["Version:  2.3.0\n","Eager mode:  True\n","GPU is available\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dkt4KgLYDAhi","executionInfo":{"status":"ok","timestamp":1603303772578,"user_tz":-330,"elapsed":1365,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}},"outputId":"e35a6d38-a1d4-4e83-98dd-bf2e382989a1","colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["#2 A. Print atleast two tweets \n","print( 'Negative Class (Tweet) : '+df_train.iloc[1]['text'])\n","print( 'Positive Class (Tweet) : '+df_train.iloc[-1]['text'])"],"execution_count":83,"outputs":[{"output_type":"stream","text":["Negative Class (Tweet) : is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n","Positive Class (Tweet) : happy #charitytuesday @theNSPCC @SparksCharity @SpeakingUpH4H \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-OqvrfQ2DL3f","executionInfo":{"status":"ok","timestamp":1603303782193,"user_tz":-330,"elapsed":1186,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}},"outputId":"adc1e4cb-feba-49cd-a6f7-b3d7796fc441","colab":{"base_uri":"https://localhost:8080/","height":282}},"source":["#2 B . Plot a bar graph\n","df_train.sentiment.hist()"],"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7fdab90cebe0>"]},"metadata":{"tags":[]},"execution_count":84},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"KpT1uOfAg8ps","executionInfo":{"status":"ok","timestamp":1603298474260,"user_tz":-330,"elapsed":2802,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}},"outputId":"8efc01a7-1650-480e-b8ff-e6bdbac49ccb","colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["# 2 D. Print the shapes of train and test data\n","# idx=np.random.randint(0,8000,8000)\n","# test_idx=np.concatenate((idx,idx+8000))\n","\n","# print(idx)\n","# X_test=df_train.iloc[test_idx]\n","# X_test=X_test.columns[]\n","# y_test=y_label[test_idx]\n","\n","# X_train = df_train.drop(test_idx)\n","# # X_train=np.delete(data,test_idx,axis=0)\n","# y_train=np.delete(y_label,test_idx ,axis=0)\n","\n","print('X_train shape : '+ str(X_train.shape))\n","print('y_train shape : '+ str(y_train.shape))\n","print('X_test  shape : '+ str(X_test.shape))\n","print('y_test  shape : '+ str(y_test.shape))"],"execution_count":71,"outputs":[{"output_type":"stream","text":["X_train shape : (800000, 2)\n","y_train shape : (800000, 2)\n","X_test  shape : (100000, 2)\n","y_test  shape : (100000, 2)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bDvtUhzHDYt0"},"source":["3.Data Pre-processing"]},{"cell_type":"code","metadata":{"id":"olEnkzDQg7tO","executionInfo":{"status":"ok","timestamp":1603301280524,"user_tz":-330,"elapsed":2780058,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}},"outputId":"409e3d47-5bd4-4561-e1fe-8f138791747a","colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["#3 A. Preprocessing of tweets data by removing stopwords\n","\n","print(3)\n","def text_processing(tweet):\n","    \n","    \n","    # remove https links\n","    clean_tweet = re.sub(r'http\\S+', '', tweet)\n","    # remove punctuation marks\n","    punctuation = '!\"#$%&()*+-/:;<=>?@[\\\\]^_`{|}~'\n","    clean_tweet = ''.join(ch for ch in clean_tweet if ch not in set(punctuation))\n","    # convert text to lowercase\n","    clean_tweet = clean_tweet.lower()\n","    # remove numbers\n","    clean_tweet = re.sub('\\d', ' ', clean_tweet)\n","    # remove whitespaces\n","    clean_tweet = ' '.join(clean_tweet.split())\n","    return clean_tweet\n","\n","\n","print(4)\n","# function to lemmatize text\n","def lemmatization(tweets):\n","    lemma_tweet = []\n","    for i in tweets:\n","        t = [token.lemma_ for token in nlp(i)]\n","        lemma_tweet.append(' '.join(t))\n","    return lemma_tweet\n","\n","# nlp = spacy.load('en_core_web_sm')\n","nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n","print(5)\n","X_train['clean_tweet'] = X_train['text'].apply(lambda x: text_processing(x))\n","X_test['clean_tweet'] = X_test['text'].apply(lambda x: text_processing(x))\n","print(6)\n","X_train['clean_tweet'] = lemmatization(X_train['clean_tweet'])\n","X_test['clean_tweet'] = lemmatization(X_test['clean_tweet'])\n","\n","print(7)"],"execution_count":72,"outputs":[{"output_type":"stream","text":["3\n","4\n","5\n","6\n","7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aGtJVzTOgH4-","executionInfo":{"status":"ok","timestamp":1603301288111,"user_tz":-330,"elapsed":7579,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}}},"source":["X_train.to_csv('/content/drive/My Drive/Colab Notebooks/data/X_train.csv')\n","X_test.to_csv('/content/drive/My Drive/Colab Notebooks/data/X_test.csv')\n","\n","np.save('/content/drive/My Drive/Colab Notebooks/data/y_train',y_train)\n","np.save('/content/drive/My Drive/Colab Notebooks/data/y_test',y_test)"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"id":"3pi57TVKsgQO","executionInfo":{"status":"ok","timestamp":1603301544977,"user_tz":-330,"elapsed":3893,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}}},"source":["# Load the clean train set and test set\n","X_train=pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/X_train.csv')\n","X_test =pd.read_csv('/content/drive/My Drive/Colab Notebooks/data/X_test.csv')\n","\n","y_train= np.load('/content/drive/My Drive/Colab Notebooks/data/y_train.npy')\n","y_test= np.load('/content/drive/My Drive/Colab Notebooks/data/y_test.npy')\n","\n","X_train = X_train[\"clean_tweet\"].values\n","X_test = X_test[\"clean_tweet\"].values\n"],"execution_count":74,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DgeKCBDzMlR1"},"source":["Model Building and compilation"]},{"cell_type":"code","metadata":{"id":"OacffqVEZkRd","executionInfo":{"status":"ok","timestamp":1603301589664,"user_tz":-330,"elapsed":2108,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}},"outputId":"dbb71231-23ba-4a65-9f67-d81dc5e9e21f","colab":{"base_uri":"https://localhost:8080/","height":541}},"source":["#3 B.Please use this pre-trained embedding layer from TensorFlow hub for this assignment\n","MODEL = \"nnlm-en-dim128\"\n","VERSION = 2\n","URL = \"https://tfhub.dev/google/\"+MODEL+\"/\"+str(VERSION)\n","print (URL)\n","\n","\n","# 4. Sequential Model layers- Using 3 dense layers with L2 regularization to all the layers and one layer of dropout with every layer\n","hub_layer1 = hub.KerasLayer(URL, output_shape=[128], \n","                           input_shape=[], \n","                           dtype=tf.string\n","                          )\n","model = keras.Sequential()\n","model.add(hub_layer1)\n","model.add(keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01),activity_regularizer=regularizers.l2(0.01)))\n","model.add(keras.layers.Dropout(0.5))\n","model.add(keras.layers.Dense(64, activation='relu',kernel_regularizer=regularizers.l2(0.01),activity_regularizer=regularizers.l2(0.01)))\n","model.add(keras.layers.Dropout(0.5))\n","model.add(keras.layers.Dense(32, activation='relu',kernel_regularizer=regularizers.l2(0.01),activity_regularizer=regularizers.l2(0.01)))\n","model.add(keras.layers.Dropout(0.5))\n","model.add(keras.layers.Dense(2, activation='softmax'))\n","\n","# Reasons :- Add one layer of dropout at the appropriate position and give reasons.\n","# Dropout is just a regularization technique for preventing overfitting in the network. It sets a node's weight to zero with a given probability\n","# during training, reducing the number of weights required for training at each iteration. It can be applied for each layer of the network \n","# (regardless if it is fully connected or convolutional), or after selected layers. To which layers dropout is applied is really just a design decision for what results in best performance.\n","\n","model.summary()\n","\n","#5 Compile the model with the appropriate loss function and appropriate optimizer.\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","#Reaons : Use an appropriate optimizer. Give reasons for the choice of learning rate and its value\n","# Adam combines the best properties of the AdaGrad and RMSProp algorithms to provide an optimization algorithm that can handle sparse gradients on noisy problems.\n","# The method is too fast and converges rapidly.\n","# Rectifies vanishing learning rate, high variance.\n"],"execution_count":76,"outputs":[{"output_type":"stream","text":["https://tfhub.dev/google/nnlm-en-dim128/2\n","WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fdac01110d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fdac01110d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fdac00f7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function recreate_function.<locals>.restored_function_body at 0x7fdac00f7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","keras_layer_6 (KerasLayer)   (None, 128)               124642688 \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 128)               16512     \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 32)                0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 2)                 66        \n","=================================================================\n","Total params: 124,669,602\n","Trainable params: 26,914\n","Non-trainable params: 124,642,688\n","_________________________________________________________________\n","8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XP5KhsEVNUgg"},"source":["Model Training"]},{"cell_type":"code","metadata":{"id":"CkiOXHlbZk1S","executionInfo":{"status":"ok","timestamp":1603303696371,"user_tz":-330,"elapsed":2102262,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}},"outputId":"c8d46107-ab38-4dc5-fbc1-7d951bf9182b","colab":{"base_uri":"https://localhost:8080/","height":857}},"source":["# 6 A. Train the model for an appropriate number of epochs\n","# model.load_weights('/content/drive/My Drive/Colab Notebooks/data/model.weights')\n","\n","hist = model.fit(X_train, \n","                 y_train, \n","                 epochs=25, \n","                 batch_size=64, \n","                 validation_split=.3,\n","                 verbose = 1)"],"execution_count":77,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n","8750/8750 [==============================] - 84s 10ms/step - loss: 0.6540 - accuracy: 0.6954 - val_loss: 0.6091 - val_accuracy: 0.7106\n","Epoch 2/25\n","8750/8750 [==============================] - 83s 9ms/step - loss: 0.6216 - accuracy: 0.7050 - val_loss: 0.5937 - val_accuracy: 0.7225\n","Epoch 3/25\n","8750/8750 [==============================] - 84s 10ms/step - loss: 0.6192 - accuracy: 0.7059 - val_loss: 0.5902 - val_accuracy: 0.7232\n","Epoch 4/25\n","8750/8750 [==============================] - 84s 10ms/step - loss: 0.6173 - accuracy: 0.7060 - val_loss: 0.5938 - val_accuracy: 0.7136\n","Epoch 5/25\n","8750/8750 [==============================] - 84s 10ms/step - loss: 0.6165 - accuracy: 0.7061 - val_loss: 0.5855 - val_accuracy: 0.7214\n","Epoch 6/25\n","8750/8750 [==============================] - 83s 9ms/step - loss: 0.6155 - accuracy: 0.7063 - val_loss: 0.5894 - val_accuracy: 0.7169\n","Epoch 7/25\n","8750/8750 [==============================] - 85s 10ms/step - loss: 0.6148 - accuracy: 0.7061 - val_loss: 0.5969 - val_accuracy: 0.7172\n","Epoch 8/25\n","8750/8750 [==============================] - 84s 10ms/step - loss: 0.6151 - accuracy: 0.7059 - val_loss: 0.5946 - val_accuracy: 0.7226\n","Epoch 9/25\n","8750/8750 [==============================] - 85s 10ms/step - loss: 0.6146 - accuracy: 0.7054 - val_loss: 0.5839 - val_accuracy: 0.7218\n","Epoch 10/25\n","8750/8750 [==============================] - 84s 10ms/step - loss: 0.6150 - accuracy: 0.7058 - val_loss: 0.5865 - val_accuracy: 0.7222\n","Epoch 11/25\n","8750/8750 [==============================] - 84s 10ms/step - loss: 0.6143 - accuracy: 0.7056 - val_loss: 0.5806 - val_accuracy: 0.7225\n","Epoch 12/25\n","8750/8750 [==============================] - 84s 10ms/step - loss: 0.6140 - accuracy: 0.7055 - val_loss: 0.6076 - val_accuracy: 0.6895\n","Epoch 13/25\n","8750/8750 [==============================] - 84s 10ms/step - loss: 0.6146 - accuracy: 0.7054 - val_loss: 0.5889 - val_accuracy: 0.7240\n","Epoch 14/25\n","8750/8750 [==============================] - 84s 10ms/step - loss: 0.6149 - accuracy: 0.7056 - val_loss: 0.5866 - val_accuracy: 0.7193\n","Epoch 15/25\n","8750/8750 [==============================] - 83s 9ms/step - loss: 0.6142 - accuracy: 0.7054 - val_loss: 0.5795 - val_accuracy: 0.7224\n","Epoch 16/25\n","8750/8750 [==============================] - 83s 10ms/step - loss: 0.6142 - accuracy: 0.7054 - val_loss: 0.5975 - val_accuracy: 0.7109\n","Epoch 17/25\n","8750/8750 [==============================] - 83s 9ms/step - loss: 0.6141 - accuracy: 0.7055 - val_loss: 0.6083 - val_accuracy: 0.6999\n","Epoch 18/25\n","8750/8750 [==============================] - 84s 10ms/step - loss: 0.6143 - accuracy: 0.7048 - val_loss: 0.5841 - val_accuracy: 0.7219\n","Epoch 19/25\n","8750/8750 [==============================] - 85s 10ms/step - loss: 0.6139 - accuracy: 0.7050 - val_loss: 0.5937 - val_accuracy: 0.7104\n","Epoch 20/25\n","8750/8750 [==============================] - 85s 10ms/step - loss: 0.6143 - accuracy: 0.7044 - val_loss: 0.5865 - val_accuracy: 0.7230\n","Epoch 21/25\n","8750/8750 [==============================] - 85s 10ms/step - loss: 0.6140 - accuracy: 0.7048 - val_loss: 0.5814 - val_accuracy: 0.7235\n","Epoch 22/25\n","8750/8750 [==============================] - 85s 10ms/step - loss: 0.6147 - accuracy: 0.7045 - val_loss: 0.5848 - val_accuracy: 0.7229\n","Epoch 23/25\n","8750/8750 [==============================] - 85s 10ms/step - loss: 0.6141 - accuracy: 0.7046 - val_loss: 0.5845 - val_accuracy: 0.7221\n","Epoch 24/25\n","8750/8750 [==============================] - 85s 10ms/step - loss: 0.6140 - accuracy: 0.7044 - val_loss: 0.5909 - val_accuracy: 0.7188\n","Epoch 25/25\n","8750/8750 [==============================] - 84s 10ms/step - loss: 0.6148 - accuracy: 0.7048 - val_loss: 0.5813 - val_accuracy: 0.7232\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bWY0pBJONjD2"},"source":["Model Evalutaion"]},{"cell_type":"code","metadata":{"id":"SAEnO-Bla6Aj","executionInfo":{"status":"ok","timestamp":1603303718261,"user_tz":-330,"elapsed":9729,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}}},"source":["# model.save_weights('/content/drive/My Drive/Colab Notebooks/data/model.weights')\n","y_pred=model.predict(X_test)\n"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"id":"0j_4PLACvW_Q","executionInfo":{"status":"ok","timestamp":1603303724469,"user_tz":-330,"elapsed":2035,"user":{"displayName":"BHUWAN CHANDRA BISHT","photoUrl":"","userId":"01525077315357961579"}},"outputId":"423bcf66-6672-4677-872a-b8e8811a34a6","colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["# confusion matrix\n","# print(y_pred)\n","# print(y_test)\n","y_pred\n","y_actual = []\n","y = []\n","for i,j in y_pred:\n","    if i >= 0.5:\n","      i=1\n","    else:\n","      i=0\n","\n","    if j >= 0.5:\n","      j=1\n","    else:\n","      j=0\n","    y.append(int(i))\n","\n","for k,l in y_test:\n","    y_actual.append(int(k))\n","\n","\n","# print(y)\n","y_predicted = y\n","cm =  ConfusionMatrix(y_actual , y_predicted)\n","print('Accuracy : '+ str(cm.ACC_Macro))\n","cm.print_matrix()"],"execution_count":80,"outputs":[{"output_type":"stream","text":["Accuracy : 0.7265\n","Predict     0           1           \n","Actual\n","0           33953       16276       \n","\n","1           11074       38697       \n","\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aSyjTR9yRgz0"},"source":["# Hyperparameter Tuning \n","# 1. Batch size \n","# The batch size is a hyperparameter of gradient descent that controls the number of training samples to work through before the modelâ€™s internal parameters are updated.\n","# Results: Larger batch sizes will results in larger gradient steps than smaller batch sizes for the same number of samples seen.\n","\n","# 2. Optimiser\n","# Optimiser are algorithms or methods used to change the attributes of your neural network such as weights and learning rate in order to reduce the losses. \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NP9qIanvT6dv"},"source":["# Model 1-- Base Model Train and Test Accuracy ~70%\n","\n","# Model 2-- Increasing the number of hidden layers increases Train Accuracy 71% Test Accuracy 70%\n","\n","# Model 3-- Using Different Optimiser and Regularization Values Train Accuracy ~80% and Test accuracy 73%\n","\n","# By Hypertuning we did achive an increase in accuracy compared to Base model\n","\n","# In model 2 By adding additional dropout and increasing the number of nodes we were able to see an increase in Train Accuracy\n","\n","# In Model 3 we used Stochastic gradient descent optimizer and also reduced the regularizer coefficient value which helped in increasing the over all model accuracy"],"execution_count":null,"outputs":[]}]}